Started by user admin
Obtained Jenkinsfile from git https://github.com/omarmansor/cicd-pipeline-train-schedule-autodeploy.git
[Pipeline] Start of Pipeline
[Pipeline] node
Running on Test-Server in /home/ec2-user/workspace/Abstergo-pipeline
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Declarative: Checkout SCM)
[Pipeline] checkout
Selected Git installation does not exist. Using Default
The recommended git tool is: NONE
No credentials specified
Fetching changes from the remote Git repository
Checking out Revision db9e0c416f45432aa47189df7fc96a25585846aa (refs/remotes/origin/master)
Commit message: "updated worker node agent"
 > git rev-parse --resolve-git-dir /home/ec2-user/workspace/Abstergo-pipeline/.git # timeout=10
 > git config remote.origin.url https://github.com/omarmansor/cicd-pipeline-train-schedule-autodeploy.git # timeout=10
Fetching upstream changes from https://github.com/omarmansor/cicd-pipeline-train-schedule-autodeploy.git
 > git --version # timeout=10
 > git --version # 'git version 2.38.1'
 > git fetch --tags --force --progress -- https://github.com/omarmansor/cicd-pipeline-train-schedule-autodeploy.git +refs/heads/*:refs/remotes/origin/* # timeout=10
 > git rev-parse refs/remotes/origin/master^{commit} # timeout=10
 > git config core.sparsecheckout # timeout=10
 > git checkout -f db9e0c416f45432aa47189df7fc96a25585846aa # timeout=10
 > git rev-list --no-walk db9e0c416f45432aa47189df7fc96a25585846aa # timeout=10
[Pipeline] }
[Pipeline] // stage
[Pipeline] withEnv
[Pipeline] {
[Pipeline] withEnv
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Declarative: Tool Install)
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] }
[Pipeline] // stage
[Pipeline] withEnv
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Build)
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] withEnv
[Pipeline] {
[Pipeline] echo
Running build automation
[Pipeline] sh
+ ./gradlew build -s --no-daemon
:nodeSetup UP-TO-DATE
:npmSetup UP-TO-DATE
:npmInstall UP-TO-DATE
:npm_test

> cicd-pipeline-train-schedule-git@0.0.0 test /home/ec2-user/workspace/Abstergo-pipeline
> mocha



  Index Page
[0mGET / [32m200 [0m464.418 ms - 829[0m
    âœ“ renders successfully (513ms)

  Trains API
[0mGET /trains [32m200 [0m3.073 ms - 1093[0m
    âœ“ returns data successfully


  2 passing (531ms)

:npm_build
:zip UP-TO-DATE
:build UP-TO-DATE

BUILD SUCCESSFUL in 13s
6 actionable tasks: 2 executed, 4 up-to-date
[Pipeline] archiveArtifacts
Archiving artifacts
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Build Docker Image)
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] withEnv
[Pipeline] {
[Pipeline] script
[Pipeline] {
[Pipeline] isUnix
[Pipeline] withEnv
[Pipeline] {
[Pipeline] sh
+ docker build -t omarmansor/train-schedule .
Sending build context to Docker daemon  589.3kB

Step 1/7 : FROM node:carbon
 ---> 8eeadf3757f4
Step 2/7 : WORKDIR /usr/src/app
 ---> Using cache
 ---> 2d2dbe244401
Step 3/7 : COPY package*.json ./
 ---> Using cache
 ---> e42a32c2eb58
Step 4/7 : RUN npm install
 ---> Using cache
 ---> 9174e8288436
Step 5/7 : COPY . .
 ---> Using cache
 ---> 3ba751714923
Step 6/7 : EXPOSE 8080
 ---> Using cache
 ---> 1059295b2254
Step 7/7 : CMD [ "npm", "start" ]
 ---> Using cache
 ---> e5d931922671
Successfully built e5d931922671
Successfully tagged omarmansor/train-schedule:latest
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] isUnix
[Pipeline] withEnv
[Pipeline] {
[Pipeline] sh
+ docker inspect -f . omarmansor/train-schedule
.
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] withDockerContainer
Test-Server does not seem to be running inside a container
$ docker run -t -d -u 1000:1000 -w /home/ec2-user/workspace/Abstergo-pipeline -v /home/ec2-user/workspace/Abstergo-pipeline:/home/ec2-user/workspace/Abstergo-pipeline:rw,z -v /home/ec2-user/workspace/Abstergo-pipeline@tmp:/home/ec2-user/workspace/Abstergo-pipeline@tmp:rw,z -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** omarmansor/train-schedule cat
$ docker top 86ce2325eb594ff66651feafeae543eb7c0222f9f644bfa89eb9719fd7fe5a8d -eo pid,comm
[Pipeline] {
[Pipeline] sh
+ echo Hello, World!
Hello, World!
[Pipeline] }
$ docker stop --time=1 86ce2325eb594ff66651feafeae543eb7c0222f9f644bfa89eb9719fd7fe5a8d
$ docker rm -f --volumes 86ce2325eb594ff66651feafeae543eb7c0222f9f644bfa89eb9719fd7fe5a8d
[Pipeline] // withDockerContainer
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (Push Docker Image)
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] withEnv
[Pipeline] {
[Pipeline] script
[Pipeline] {
[Pipeline] withEnv
[Pipeline] {
[Pipeline] withDockerRegistry
Using the existing docker config file.Removing blacklisted property: auths$ docker login -u omarmansor -p ******** https://registry.hub.docker.com
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
WARNING! Your password will be stored unencrypted in /home/ec2-user/workspace/Abstergo-pipeline@tmp/cd3d6762-cd90-4e0b-8521-9b1a2d78cd48/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
[Pipeline] {
[Pipeline] isUnix
[Pipeline] withEnv
[Pipeline] {
[Pipeline] sh
+ docker tag omarmansor/train-schedule registry.hub.docker.com/omarmansor/train-schedule:36
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] isUnix
[Pipeline] withEnv
[Pipeline] {
[Pipeline] sh
+ docker push registry.hub.docker.com/omarmansor/train-schedule:36
The push refers to repository [registry.hub.docker.com/omarmansor/train-schedule]
2c20fc9cf835: Preparing
457e7b371818: Preparing
14b599741121: Preparing
79b01d9bb47d: Preparing
423451ed44f2: Preparing
b2aaf85d6633: Preparing
88601a85ce11: Preparing
42f9c2f9c08e: Preparing
99e8bd3efaaf: Preparing
bee1e39d7c3a: Preparing
1f59a4b2e206: Preparing
0ca7f54856c0: Preparing
ebb9ae013834: Preparing
b2aaf85d6633: Waiting
88601a85ce11: Waiting
42f9c2f9c08e: Waiting
99e8bd3efaaf: Waiting
bee1e39d7c3a: Waiting
1f59a4b2e206: Waiting
0ca7f54856c0: Waiting
ebb9ae013834: Waiting
79b01d9bb47d: Layer already exists
14b599741121: Layer already exists
423451ed44f2: Layer already exists
2c20fc9cf835: Layer already exists
457e7b371818: Layer already exists
88601a85ce11: Layer already exists
42f9c2f9c08e: Layer already exists
b2aaf85d6633: Layer already exists
99e8bd3efaaf: Layer already exists
bee1e39d7c3a: Layer already exists
1f59a4b2e206: Layer already exists
0ca7f54856c0: Layer already exists
ebb9ae013834: Layer already exists
36: digest: sha256:2aa0f8093883f4c524e4d4e37f0594f34b6cf84ba1dad55392d39dbe441c3387 size: 3053
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] isUnix
[Pipeline] withEnv
[Pipeline] {
[Pipeline] sh
+ docker tag omarmansor/train-schedule registry.hub.docker.com/omarmansor/train-schedule:latest
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] isUnix
[Pipeline] withEnv
[Pipeline] {
[Pipeline] sh
+ docker push registry.hub.docker.com/omarmansor/train-schedule:latest
The push refers to repository [registry.hub.docker.com/omarmansor/train-schedule]
2c20fc9cf835: Preparing
457e7b371818: Preparing
14b599741121: Preparing
79b01d9bb47d: Preparing
423451ed44f2: Preparing
b2aaf85d6633: Preparing
88601a85ce11: Preparing
42f9c2f9c08e: Preparing
99e8bd3efaaf: Preparing
bee1e39d7c3a: Preparing
1f59a4b2e206: Preparing
0ca7f54856c0: Preparing
ebb9ae013834: Preparing
b2aaf85d6633: Waiting
88601a85ce11: Waiting
42f9c2f9c08e: Waiting
99e8bd3efaaf: Waiting
bee1e39d7c3a: Waiting
1f59a4b2e206: Waiting
0ca7f54856c0: Waiting
ebb9ae013834: Waiting
457e7b371818: Layer already exists
79b01d9bb47d: Layer already exists
2c20fc9cf835: Layer already exists
423451ed44f2: Layer already exists
14b599741121: Layer already exists
42f9c2f9c08e: Layer already exists
b2aaf85d6633: Layer already exists
bee1e39d7c3a: Layer already exists
99e8bd3efaaf: Layer already exists
88601a85ce11: Layer already exists
0ca7f54856c0: Layer already exists
1f59a4b2e206: Layer already exists
ebb9ae013834: Layer already exists
latest: digest: sha256:2aa0f8093883f4c524e4d4e37f0594f34b6cf84ba1dad55392d39dbe441c3387 size: 3053
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // withDockerRegistry
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // script
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (CanaryDeploy)
[Pipeline] withEnv
[Pipeline] {
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] withEnv
[Pipeline] {
[Pipeline] kubernetesDeploy
Starting Kubernetes deployment
Finished Kubernetes deployment
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (DeployToProduction)
[Pipeline] withEnv
[Pipeline] {
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] tool
[Pipeline] envVarsForTool
[Pipeline] withEnv
[Pipeline] {
[Pipeline] input
Deploy to Production?
Proceed or Abort
Loading configuration: /home/ec2-user/workspace/Abstergo-pipeline/train-schedule-kube-canary.yml
Applied Service: Service(apiVersion=v1, kind=Service, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2023-01-04T18:20:36Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels=null, name=train-schedule-service-canary, namespace=default, ownerReferences=[], resourceVersion=7352, selfLink=null, uid=2c109b4d-00b3-413e-8c21-1dce2284e7d8, additionalProperties={managedFields=[{manager=okhttp, operation=Update, apiVersion=v1, time=2023-01-04T18:20:36Z, fieldsType=FieldsV1, fieldsV1={f:spec={f:externalTrafficPolicy={}, f:internalTrafficPolicy={}, f:ports={.={}, k:{"port":8080,"protocol":"TCP"}={.={}, f:nodePort={}, f:port={}, f:protocol={}, f:targetPort={}}}, f:selector={}, f:sessionAffinity={}, f:type={}}}}]}), spec=ServiceSpec(clusterIP=10.102.36.130, externalIPs=[], externalName=null, externalTrafficPolicy=Cluster, healthCheckNodePort=null, loadBalancerIP=null, loadBalancerSourceRanges=[], ports=[ServicePort(name=null, nodePort=30002, port=8080, protocol=TCP, targetPort=IntOrString(IntVal=8080, Kind=null, StrVal=null, additionalProperties={}), additionalProperties={})], publishNotReadyAddresses=null, selector={app=train-schedule, track=canary}, sessionAffinity=None, sessionAffinityConfig=null, type=NodePort, additionalProperties={clusterIPs=[10.102.36.130], ipFamilies=[IPv4], ipFamilyPolicy=SingleStack, internalTrafficPolicy=Cluster}), status=ServiceStatus(loadBalancer=LoadBalancerStatus(ingress=[], additionalProperties={}), additionalProperties={}), additionalProperties={})
Applied Deployment: Deployment(apiVersion=apps/v1, kind=Deployment, metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=2023-01-04T18:20:37Z, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=3, initializers=null, labels={app=train-schedule}, name=train-schedule-deployment-canary, namespace=default, ownerReferences=[], resourceVersion=7653, selfLink=null, uid=3cca0927-050c-4473-a806-e86a69908877, additionalProperties={managedFields=[{manager=kube-controller-manager, operation=Update, apiVersion=apps/v1, time=2023-01-04T18:21:02Z, fieldsType=FieldsV1, fieldsV1={f:status={f:conditions={.={}, k:{"type":"Available"}={.={}, f:lastTransitionTime={}, f:lastUpdateTime={}, f:message={}, f:reason={}, f:status={}, f:type={}}, k:{"type":"Progressing"}={.={}, f:lastTransitionTime={}, f:lastUpdateTime={}, f:message={}, f:reason={}, f:status={}, f:type={}}}, f:observedGeneration={}}}, subresource=status}, {manager=okhttp, operation=Update, apiVersion=apps/v1, time=2023-01-04T18:23:41Z, fieldsType=FieldsV1, fieldsV1={f:metadata={f:labels={.={}, f:app={}}}, f:spec={f:progressDeadlineSeconds={}, f:replicas={}, f:revisionHistoryLimit={}, f:selector={}, f:strategy={f:rollingUpdate={.={}, f:maxSurge={}, f:maxUnavailable={}}, f:type={}}, f:template={f:metadata={f:labels={.={}, f:app={}, f:track={}}}, f:spec={f:containers={k:{"name":"train-schedule"}={.={}, f:image={}, f:imagePullPolicy={}, f:livenessProbe={.={}, f:failureThreshold={}, f:httpGet={.={}, f:path={}, f:port={}, f:scheme={}}, f:initialDelaySeconds={}, f:periodSeconds={}, f:successThreshold={}, f:timeoutSeconds={}}, f:name={}, f:ports={.={}, k:{"containerPort":8080,"protocol":"TCP"}={.={}, f:containerPort={}, f:protocol={}}}, f:resources={.={}, f:requests={.={}, f:cpu={}}}, f:terminationMessagePath={}, f:terminationMessagePolicy={}}}, f:dnsPolicy={}, f:restartPolicy={}, f:schedulerName={}, f:securityContext={}, f:terminationGracePeriodSeconds={}}}}}}]}), spec=DeploymentSpec(minReadySeconds=null, paused=null, progressDeadlineSeconds=600, replicas=1, revisionHistoryLimit=10, selector=LabelSelector(matchExpressions=[], matchLabels={app=train-schedule, track=canary}, additionalProperties={}), strategy=DeploymentStrategy(rollingUpdate=RollingUpdateDeployment(maxSurge=IntOrString(IntVal=null, Kind=null, StrVal=25%, additionalProperties={}), maxUnavailable=IntOrString(IntVal=null, Kind=null, StrVal=25%, additionalProperties={}), additionalProperties={}), type=RollingUpdate, additionalProperties={}), template=PodTemplateSpec(metadata=ObjectMeta(annotations=null, clusterName=null, creationTimestamp=null, deletionGracePeriodSeconds=null, deletionTimestamp=null, finalizers=[], generateName=null, generation=null, initializers=null, labels={app=train-schedule, track=canary}, name=null, namespace=null, ownerReferences=[], resourceVersion=null, selfLink=null, uid=null, additionalProperties={}), spec=PodSpec(activeDeadlineSeconds=null, affinity=null, automountServiceAccountToken=null, containers=[Container(args=[], command=[], env=[], envFrom=[], image=omarmansor/train-schedule:36, imagePullPolicy=IfNotPresent, lifecycle=null, livenessProbe=Probe(exec=null, failureThreshold=3, httpGet=HTTPGetAction(host=null, httpHeaders=[], path=/, port=IntOrString(IntVal=8080, Kind=null, StrVal=null, additionalProperties={}), scheme=HTTP, additionalProperties={}), initialDelaySeconds=15, periodSeconds=10, successThreshold=1, tcpSocket=null, timeoutSeconds=1, additionalProperties={}), name=train-schedule, ports=[ContainerPort(containerPort=8080, hostIP=null, hostPort=null, name=null, protocol=TCP, additionalProperties={})], readinessProbe=null, resources=ResourceRequirements(limits=null, requests={cpu=Quantity(amount=200m, format=null, additionalProperties={})}, additionalProperties={}), securityContext=null, stdin=null, stdinOnce=null, terminationMessagePath=/dev/termination-log, terminationMessagePolicy=File, tty=null, volumeDevices=[], volumeMounts=[], workingDir=null, additionalProperties={})], dnsConfig=null, dnsPolicy=ClusterFirst, hostAliases=[], hostIPC=null, hostNetwork=null, hostPID=null, hostname=null, imagePullSecrets=[], initContainers=[], nodeName=null, nodeSelector=null, priority=null, priorityClassName=null, restartPolicy=Always, schedulerName=default-scheduler, securityContext=PodSecurityContext(fsGroup=null, runAsNonRoot=null, runAsUser=null, seLinuxOptions=null, supplementalGroups=[], additionalProperties={}), serviceAccount=null, serviceAccountName=null, subdomain=null, terminationGracePeriodSeconds=30, tolerations=[], volumes=[], additionalProperties={}), additionalProperties={}), additionalProperties={}), status=DeploymentStatus(availableReplicas=null, collisionCount=null, conditions=[DeploymentCondition(lastTransitionTime=2023-01-04T18:21:02Z, lastUpdateTime=2023-01-04T18:21:02Z, message=Deployment has minimum availability., reason=MinimumReplicasAvailable, status=True, type=Available, additionalProperties={}), DeploymentCondition(lastTransitionTime=2023-01-04T18:20:37Z, lastUpdateTime=2023-01-04T18:21:02Z, message=ReplicaSet "train-schedule-deployment-canary-74557c96bb" has successfully progressed., reason=NewReplicaSetAvailable, status=True, type=Progressing, additionalProperties={})], observedGeneration=2, readyReplicas=null, replicas=null, unavailableReplicas=null, updatedReplicas=null, additionalProperties={}), additionalProperties={})
Approved by admin
[Pipeline] milestone
Trying to pass milestone 1
[Pipeline] kubernetesDeploy
Starting Kubernetes deployment
Finished Kubernetes deployment
[Pipeline] kubernetesDeploy
Starting Kubernetes deployment
Finished Kubernetes deployment
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // withEnv
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
Finished: SUCCESS
